{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.0"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os.path\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"cifar-10-image-recognition.ipynb\"))))\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import model_from_json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    weight_decay = 1e-4\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_existed():\n",
    "    if os.path.isfile('model.h5'):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(weights_path):\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weights_path)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_21\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_121 (Conv2D)          (None, 32, 32, 32)        896       \n_________________________________________________________________\nactivation_121 (Activation)  (None, 32, 32, 32)        0         \n_________________________________________________________________\nbatch_normalization_121 (Bat (None, 32, 32, 32)        128       \n_________________________________________________________________\nconv2d_122 (Conv2D)          (None, 32, 32, 32)        9248      \n_________________________________________________________________\nactivation_122 (Activation)  (None, 32, 32, 32)        0         \n_________________________________________________________________\nbatch_normalization_122 (Bat (None, 32, 32, 32)        128       \n_________________________________________________________________\nmax_pooling2d_61 (MaxPooling (None, 16, 16, 32)        0         \n_________________________________________________________________\ndropout_61 (Dropout)         (None, 16, 16, 32)        0         \n_________________________________________________________________\nconv2d_123 (Conv2D)          (None, 16, 16, 64)        18496     \n_________________________________________________________________\nactivation_123 (Activation)  (None, 16, 16, 64)        0         \n_________________________________________________________________\nbatch_normalization_123 (Bat (None, 16, 16, 64)        256       \n_________________________________________________________________\nconv2d_124 (Conv2D)          (None, 16, 16, 64)        36928     \n_________________________________________________________________\nactivation_124 (Activation)  (None, 16, 16, 64)        0         \n_________________________________________________________________\nbatch_normalization_124 (Bat (None, 16, 16, 64)        256       \n_________________________________________________________________\nmax_pooling2d_62 (MaxPooling (None, 8, 8, 64)          0         \n_________________________________________________________________\ndropout_62 (Dropout)         (None, 8, 8, 64)          0         \n_________________________________________________________________\nconv2d_125 (Conv2D)          (None, 8, 8, 128)         73856     \n_________________________________________________________________\nactivation_125 (Activation)  (None, 8, 8, 128)         0         \n_________________________________________________________________\nbatch_normalization_125 (Bat (None, 8, 8, 128)         512       \n_________________________________________________________________\nconv2d_126 (Conv2D)          (None, 8, 8, 128)         147584    \n_________________________________________________________________\nactivation_126 (Activation)  (None, 8, 8, 128)         0         \n_________________________________________________________________\nbatch_normalization_126 (Bat (None, 8, 8, 128)         512       \n_________________________________________________________________\nmax_pooling2d_63 (MaxPooling (None, 4, 4, 128)         0         \n_________________________________________________________________\ndropout_63 (Dropout)         (None, 4, 4, 128)         0         \n_________________________________________________________________\nflatten_19 (Flatten)         (None, 2048)              0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 10)                20490     \n=================================================================\nTotal params: 309,290\nTrainable params: 308,394\nNon-trainable params: 896\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    " \n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "if model_existed():\n",
    "    model = load_trained_model(\"model.h5\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "else:\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=1,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_existed():\n",
    "    model_json = model.to_json()\n",
    "    with open('model.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights('model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10000/10000 [==============================] - 26s 3ms/step\n[1.7009657024383544, 0.5386999845504761]\n"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print(scores)"
   ]
  }
 ]
}